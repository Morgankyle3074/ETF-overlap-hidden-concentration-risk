{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba6de72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../data/processed')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "PROC_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18d5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etf</th>\n",
       "      <th>holding_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.077702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPY</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.066152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPY</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.051086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPY</td>\n",
       "      <td>AMAZON.COM INC</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.033212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPY</td>\n",
       "      <td>ALPHABET INC CL A</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.030750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   etf       holding_name ticker    weight\n",
       "0  SPY        NVIDIA CORP   NVDA  0.077702\n",
       "1  SPY          APPLE INC   AAPL  0.066152\n",
       "2  SPY     MICROSOFT CORP   MSFT  0.051086\n",
       "3  SPY     AMAZON.COM INC   AMZN  0.033212\n",
       "4  SPY  ALPHABET INC CL A  GOOGL  0.030750"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_clean(etf: str) -> pd.DataFrame:\n",
    "    pqt = PROC_DIR / f\"{etf.lower()}_clean.parquet\"\n",
    "    csv = PROC_DIR / f\"{etf.lower()}_clean.csv\"\n",
    "\n",
    "    if pqt.exists():\n",
    "        return pd.read_parquet(pqt)\n",
    "\n",
    "    if csv.exists():\n",
    "        return pd.read_csv(csv)\n",
    "\n",
    "    raise FileNotFoundError(f\"Missing clean file for {etf}\")\n",
    "\n",
    "spy  = load_clean(\"SPY\")\n",
    "voo  = load_clean(\"VOO\")\n",
    "qqq  = load_clean(\"QQQ\")\n",
    "schd = load_clean(\"SCHD\")\n",
    "\n",
    "holdings = pd.concat([spy, voo, qqq, schd], ignore_index=True)\n",
    "holdings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b19ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holding_name\n",
       "NVIDIA CORP                   0.060876\n",
       "APPLE INC                     0.051288\n",
       "MICROSOFT CORP                0.040921\n",
       "AMAZON.COM INC                0.028553\n",
       "BROADCOM INC                  0.020837\n",
       "TESLA INC                     0.020361\n",
       "META PLATFORMS INC            0.015825\n",
       "CISCO SYSTEMS INC             0.015239\n",
       "PEPSICO INC                   0.014927\n",
       "ALPHABET INC                  0.014900\n",
       "AMGEN INC                     0.013737\n",
       "WALMART INC                   0.013606\n",
       "CHEVRON CORP                  0.013526\n",
       "LOCKHEED MARTIN CORP          0.012906\n",
       "VERIZON COMMUNICATIONS INC    0.012467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = holdings.pivot_table(\n",
    "    index=\"holding_name\",\n",
    "    columns=\"etf\",\n",
    "    values=\"weight\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "portfolio_weights = {\n",
    "    \"SPY\": 0.25,\n",
    "    \"VOO\": 0.25,\n",
    "    \"QQQ\": 0.25,\n",
    "    \"SCHD\": 0.25,\n",
    "}\n",
    "\n",
    "port = pd.Series(0.0, index=W.index)\n",
    "\n",
    "for etf, w in portfolio_weights.items():\n",
    "    port += w * W[etf]\n",
    "\n",
    "port = port.sort_values(ascending=False)\n",
    "\n",
    "port.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cffdcab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014165992686819026"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hhi(weights: pd.Series) -> float:\n",
    "    return float((weights ** 2).sum())\n",
    "\n",
    "hhi_value = hhi(port)\n",
    "\n",
    "hhi_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a41d2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.59159369258083"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_holdings = 1 / hhi_value\n",
    "\n",
    "effective_holdings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7391c9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPY\n",
      "HHI: 0.019939\n",
      "Effective Holdings: 50.15\n",
      "Top 10 Weight Share: 37.02 %\n",
      "================================================================================\n",
      "VOO\n",
      "HHI: 0.020744\n",
      "Effective Holdings: 48.21\n",
      "Top 10 Weight Share: 38.35 %\n",
      "================================================================================\n",
      "QQQ\n",
      "HHI: 0.031281\n",
      "Effective Holdings: 31.97\n",
      "Top 10 Weight Share: 47.38 %\n",
      "================================================================================\n",
      "SCHD\n",
      "HHI: 0.029259\n",
      "Effective Holdings: 34.18\n",
      "Top 10 Weight Share: 42.2 %\n"
     ]
    }
   ],
   "source": [
    "def concentration_metrics(df: pd.DataFrame, label: str):\n",
    "    w = df[\"weight\"]\n",
    "\n",
    "    h = hhi(w)\n",
    "    eff_n = 1 / h\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(label)\n",
    "    print(\"HHI:\", round(h, 6))\n",
    "    print(\"Effective Holdings:\", round(eff_n, 2))\n",
    "    print(\"Top 10 Weight Share:\", round(w.sort_values(ascending=False).head(10).sum()*100, 2), \"%\")\n",
    "\n",
    "concentration_metrics(spy, \"SPY\")\n",
    "concentration_metrics(voo, \"VOO\")\n",
    "concentration_metrics(qqq, \"QQQ\")\n",
    "concentration_metrics(schd, \"SCHD\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1423be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Portfolio HHI': 0.014166,\n",
       " 'Effective Holdings': 70.59,\n",
       " 'Top 10 Holdings Share (%)': np.float64(28.37),\n",
       " 'Top 20 Holdings Share (%)': np.float64(40.78),\n",
       " 'Top 50 Holdings Share (%)': np.float64(60.61)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = port.head(10).sum()\n",
    "top20 = port.head(20).sum()\n",
    "top50 = port.head(50).sum()\n",
    "\n",
    "{\n",
    "    \"Portfolio HHI\": round(hhi_value, 6),\n",
    "    \"Effective Holdings\": round(effective_holdings, 2),\n",
    "    \"Top 10 Holdings Share (%)\": round(top10*100, 2),\n",
    "    \"Top 20 Holdings Share (%)\": round(top20*100, 2),\n",
    "    \"Top 50 Holdings Share (%)\": round(top50*100, 2),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f8f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def build_weight_matrix(holdings: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = holdings.copy()\n",
    "    df[\"holding_name\"] = df[\"holding_name\"].astype(str).str.strip().str.upper()\n",
    "    df[\"etf\"] = df[\"etf\"].astype(str).str.strip().str.upper()\n",
    "    return df.pivot_table(index=\"holding_name\", columns=\"etf\", values=\"weight\", aggfunc=\"sum\", fill_value=0.0)\n",
    "\n",
    "def to_long_matrix(mat: pd.DataFrame, value_name: str) -> pd.DataFrame:\n",
    "    long = mat.copy()\n",
    "    long.index.name = \"etf_a\"\n",
    "    return long.reset_index().melt(id_vars=\"etf_a\", var_name=\"etf_b\", value_name=value_name)\n",
    "\n",
    "def hhi(weights: pd.Series) -> float:\n",
    "    w = pd.to_numeric(weights, errors=\"coerce\").fillna(0.0)\n",
    "    return float((w ** 2).sum())\n",
    "\n",
    "def summarize_concentration(weights: pd.Series) -> dict:\n",
    "    w = pd.to_numeric(weights, errors=\"coerce\").dropna()\n",
    "    h = hhi(w)\n",
    "    eff = (1 / h) if h > 0 else np.nan\n",
    "    top10 = float(w.sort_values(ascending=False).head(10).sum())\n",
    "    top20 = float(w.sort_values(ascending=False).head(20).sum())\n",
    "    top50 = float(w.sort_values(ascending=False).head(50).sum())\n",
    "    return {\"hhi\": float(h), \"effective_holdings\": float(eff),\n",
    "            \"top10_share\": top10, \"top20_share\": top20, \"top50_share\": top50}\n",
    "\n",
    "def export_tableau_extracts(out_dir: Path, holdings_clean: pd.DataFrame, portfolio: dict | None = None):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # base holdings\n",
    "    (out_dir / \"holdings_clean_long.csv\").write_text(\"\")  # ensure folder exists\n",
    "    holdings_clean.to_csv(out_dir / \"holdings_clean_long.csv\", index=False)\n",
    "\n",
    "    # overlap\n",
    "    W = build_weight_matrix(holdings_clean)\n",
    "    present = (W > 0).astype(int)\n",
    "    overlap_count = present.T @ present\n",
    "    holding_counts = present.sum(axis=0)\n",
    "    overlap_pct = overlap_count.copy().astype(float)\n",
    "    for a in overlap_pct.index:\n",
    "        overlap_pct.loc[a, :] = overlap_pct.loc[a, :] / float(holding_counts[a])\n",
    "\n",
    "    weighted_overlap = pd.DataFrame(index=W.columns, columns=W.columns, dtype=float)\n",
    "    for a in W.columns:\n",
    "        for b in W.columns:\n",
    "            weighted_overlap.loc[a, b] = np.minimum(W[a], W[b]).sum()\n",
    "\n",
    "    to_long_matrix(weighted_overlap, \"overlap_weighted\").to_csv(out_dir / \"overlap_weighted_long.csv\", index=False)\n",
    "    to_long_matrix(overlap_count, \"overlap_count\").to_csv(out_dir / \"overlap_count_long.csv\", index=False)\n",
    "    to_long_matrix(overlap_pct, \"overlap_pct_of_a\").to_csv(out_dir / \"overlap_pct_long.csv\", index=False)\n",
    "\n",
    "    # concentration metrics\n",
    "    rows = []\n",
    "    for etf in [\"SPY\", \"VOO\", \"QQQ\", \"SCHD\"]:\n",
    "        w = holdings_clean.loc[holdings_clean[\"etf\"].str.upper() == etf, \"weight\"]\n",
    "        s = summarize_concentration(w)\n",
    "        rows.append({\"entity_type\": \"ETF\", \"entity_name\": etf, **s})\n",
    "\n",
    "    # portfolio extracts\n",
    "    if portfolio is not None:\n",
    "        port = pd.Series(0.0, index=W.index)\n",
    "        for etf, wt in portfolio.items():\n",
    "            port += float(wt) * W[etf.upper()]\n",
    "        port = port.sort_values(ascending=False)\n",
    "\n",
    "        s = summarize_concentration(port)\n",
    "        rows.append({\"entity_type\": \"PORTFOLIO\", \"entity_name\": \"CUSTOM_PORTFOLIO\", **s})\n",
    "\n",
    "        port_df = port.head(200).reset_index()\n",
    "        port_df.columns = [\"holding_name\", \"portfolio_weight\"]\n",
    "        port_df.to_csv(out_dir / \"portfolio_holdings_top200.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(out_dir / \"concentration_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fd1d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['concentration_metrics.csv',\n",
       " 'holdings_clean_long.csv',\n",
       " 'overlap_count_long.csv',\n",
       " 'overlap_pct_long.csv',\n",
       " 'overlap_weighted_long.csv',\n",
       " 'portfolio_holdings_top200.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(\"..\")\n",
    "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR = PROJECT_ROOT / \"data\" / \"tableau_extracts\"\n",
    "\n",
    "spy  = pd.read_parquet(PROC_DIR / \"spy_clean.parquet\")\n",
    "voo  = pd.read_parquet(PROC_DIR / \"voo_clean.parquet\")\n",
    "qqq  = pd.read_parquet(PROC_DIR / \"qqq_clean.parquet\")\n",
    "schd = pd.read_parquet(PROC_DIR / \"schd_clean.parquet\")\n",
    "\n",
    "holdings_clean = pd.concat([spy, voo, qqq, schd], ignore_index=True)\n",
    "\n",
    "export_tableau_extracts(\n",
    "    OUT_DIR,\n",
    "    holdings_clean,\n",
    "    portfolio={\"SPY\":0.25, \"VOO\":0.25, \"QQQ\":0.25, \"SCHD\":0.25}\n",
    ")\n",
    "\n",
    "sorted([p.name for p in OUT_DIR.glob(\"*.csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef18b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
